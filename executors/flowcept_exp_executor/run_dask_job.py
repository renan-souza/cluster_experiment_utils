import sys
import argparse
import os
from dataclasses import dataclass
from pathlib import Path
from time import time
import json
from datetime import datetime

from omegaconf import OmegaConf, DictConfig

from cluster_experiment_utils.cluster_utils.base_cluster_utils import BaseClusterUtils
from cluster_experiment_utils.cluster_utils.lsf_utils import LsfUtils
from cluster_experiment_utils.cluster_utils.slurm_utils import SlurmUtils
from cluster_experiment_utils.flowcept_utils import (
    update_flowcept_settings,
    kill_dbs,
    start_redis,
    start_mongo,
    test_data_and_persist,
)

from cluster_experiment_utils.utils import run_cmd_check_output, printed_sleep, run_cmd


@dataclass
class Args:
    my_job_id: str = None
    conf: str = None  # Path
    varying_param_key: str = None


def parse_args():
    parser = argparse.ArgumentParser(description="Submit Dask Job.")

    parser.add_argument(
        "--my-job-id", metavar="i", required=True, help="job id generated by our script"
    )

    parser.add_argument("--conf", help="Yaml configuration file", required=True)

    parser.add_argument("--varying_param_key", required=True)

    if len(sys.argv) == 1:
        parser.print_help()

    ags = parser.parse_args()
    return Args(
        my_job_id=ags.my_job_id, conf=ags.conf, varying_param_key=ags.varying_param_key
    )


def start_scheduler(
    cluster_scheduler_type, preload_scheduler_cmd, rep_dir, scheduler_file
):
    print("Starting Scheduler")
    # Check if cluster_scheduler_type it is slurm or lsf and change accordingly below
    run_cmd(
        f"jsrun --gpu_per_rs 0 --nrs 1 --tasks_per_rs 1 "
        f"--cpu_per_rs 1 --rs_per_host 1 "
        f"-e individual "
        f"--stdio_stdout {rep_dir}/scheduler_out.%h.%j.%t.%p "
        f"--stdio_stderr {rep_dir}/scheduler_err.%h.%j.%t.%p "
        f"dask scheduler "
        f"{preload_scheduler_cmd} "
        f"--interface='ib0' --no-dashboard --no-show "
        f"--scheduler-file {scheduler_file} &"
    )
    total_wait_time = 160  # in seconds
    print(
        f"Waiting up to {total_wait_time} seconds so the scheduler file can be created."
    )
    wait_time = 3
    start_waiting_time = time()
    elapsed_time = 0
    while not os.path.exists(scheduler_file) and elapsed_time < total_wait_time:
        printed_sleep(wait_time)
        elapsed_time = time() - start_waiting_time
        print(f"Still waiting for {scheduler_file}")
    if os.path.exists(scheduler_file):
        print(f"File '{scheduler_file}' found after {elapsed_time} seconds")
        print("Scheduler started!")
        return True
    else:
        print(f"File '{scheduler_file}' not found after {total_wait_time} seconds")
        return False


def start_workers(cluster_scheduler_type, nnodes, rep_dir, scheduler_file):
    # Start Workers
    # Each Summit node has 2 sockets, each socket with 21 physical cores (42 physical cores in total), each with 4 hardware threads.
    NO_PHYSICAL_THREADS_PER_CORE = 4
    NO_CPUS_PER_NODE = 42
    worker_logs = os.path.join(rep_dir, "worker_logs")
    os.makedirs(worker_logs, exist_ok=True)
    n_workers = (
        nnodes * NO_CPUS_PER_NODE - 1
    )  # -1 because we leave 1 RS for the scheduler
    for i in range(0, n_workers):
        print(f"Starting worker {i}")
        run_cmd(
            f"jsrun --nrs 1 "
            f"--rs_per_host 1 "  # create one RS per physical core
            f"--cpu_per_rs 1 "  # 1 dask worker per physical core
            f"--gpu_per_rs 0 "  # we dont use gpu
            f"--tasks_per_rs 1 "  # 1 dask worker per physical core
            f"--smpiargs='none' "
            f"-e individual "
            f"--stdio_stdout {worker_logs}/worker_out.%h.%j.%t.%p "
            f"--stdio_stderr {worker_logs}/worker_err.%h.%j.%t.%p "
            f"--latency_priority cpu-cpu "
            # f"-bpacked:4 "
            f"dask worker --nthreads {NO_PHYSICAL_THREADS_PER_CORE} --nworkers 1 --interface ib0 --no-dashboard  --scheduler-file '{scheduler_file}' &"
        )

    print(f"\n\nDone starting {n_workers} workers. Let's just wait some time...\n\n")
    printed_sleep(30)


def start_client(conf_data, varying_param_key, with_flowcept_arg):
    print("Starting the Client")
    python_client_command = conf_data.static_params.dask_client_script
    # TODO: what to change below?
    wf_params = conf_data["varying_params"][varying_param_key]["workflow_params"]
    # TODO: save them?

    for k, v in wf_params.items():
        python_client_command = python_client_command.replace("${" + k + "_val}", v)
    python_client_command += with_flowcept_arg
    t_c_i = time()
    run_cmd_check_output(python_client_command)

    t_c_f = time()
    printed_sleep(15)
    return t_c_f, t_c_i


def start_flowcept(
    cluster_utils,
    exp_conf,
    job_hosts,
    rep_dir,
    varying_param_key,
):
    container_images_dir = exp_conf.static_params.container_images_dir
    redis_image = os.path.join(container_images_dir, "redis.sif")
    should_start_mongo = exp_conf.static_params.start_mongo
    flowcept_base_settings_path = exp_conf["static_params"][
        "flowcept_base_settings_path"
    ]
    dask_scheduler_setup_path = exp_conf["static_params"]["dask_scheduler_setup_path"]
    preload_scheduler_cmd = f"--preload {dask_scheduler_setup_path}"
    flowcept_settings = OmegaConf.load(Path(flowcept_base_settings_path))
    # On Summit, the first node, ie the [0] in host_counts below, is
    # a batch node. We're forcing here the db to run on a compute node.
    db_host = list(job_hosts.keys())[1]
    print(f"DB Host: {db_host}")
    job_id = cluster_utils.get_this_job_id()
    update_flowcept_settings(
        exp_conf,
        flowcept_settings,
        db_host,
        should_start_mongo,
        rep_dir,
        varying_param_key,
        job_id,
    )
    kill_dbs(db_host, should_start_mongo)
    start_redis(db_host, redis_image)
    if should_start_mongo:
        mongo_image = os.path.join(container_images_dir, "mongo.sif")
        start_mongo(db_host, mongo_image, rep_dir)

    from flowcept import FlowceptConsumerAPI

    consumer = FlowceptConsumerAPI()
    consumer.start()
    return consumer, flowcept_settings, preload_scheduler_cmd


def main(
    cluster_utils: BaseClusterUtils,
    exp_conf: DictConfig,
    varying_param_key: str,
    my_job_id,
    rep_no: int,
):
    cluster_scheduler_type = exp_conf.scheduler_type
    proj_dir = exp_conf.static_params.proj_dir
    job_dir = os.path.join(proj_dir, "exps", my_job_id)
    rep_dir = os.path.join(job_dir, str(rep_no))
    os.makedirs(rep_dir, exist_ok=True)
    nnodes = exp_conf.varying_params[varying_param_key].get("nnodes")
    scheduler_file = os.path.join(rep_dir, "scheduler_info.json")

    with_flowcept = exp_conf.varying_params[varying_param_key].get(
        "with_flowcept", False
    )
    with_flowcept_arg = "--with-flowcept" if with_flowcept else ""
    # db_host = None

    os.environ["LC_ALL"] = "C"
    os.environ["LANG"] = "C"
    python_env = run_cmd_check_output("which python")
    print(f"Using python: {python_env}")  # TODO: save this in the workflow?

    job_hosts = cluster_utils.get_job_hosts()
    host_allocs = {}  # not sure if we are going to need this
    preload_scheduler_cmd = ""

    t0 = time()
    # run_cmd(f"jskill all ") TODO?
    printed_sleep(2)

    consumer = None
    flowcept_settings = None
    if with_flowcept:
        consumer, flowcept_settings, preload_scheduler_cmd = start_flowcept(
            cluster_utils,
            exp_conf,
            job_hosts,
            rep_dir,
            varying_param_key,
        )

    if not start_scheduler(
        cluster_scheduler_type, preload_scheduler_cmd, rep_dir, scheduler_file
    ):
        return -1

    printed_sleep(3)
    start_workers(cluster_scheduler_type, nnodes, rep_dir, scheduler_file)

    t_c_f, t_c_i = start_client(exp_conf, varying_param_key, with_flowcept_arg)
    print("Workflow done!")
    if consumer is not None:
        print("Now going to gracefully stop everything")
        consumer.stop()

    with open(f"{rep_dir}/workflow_result.json", "r") as infile:
        wf_result = json.load(infile)

    t1 = time()
    job_output = cluster_utils.generate_job_output(
        cluster_utils,
        exp_conf,
        host_allocs,
        job_hosts,
        job_dir,
        my_job_id,
        proj_dir,
        python_env,
        rep_dir,
        rep_no,
        t0,
        t1,
        t_c_f,
        t_c_i,
        varying_param_key,
        wf_result,
        with_flowcept,
        flowcept_settings,
    )

    if with_flowcept:
        test_data_and_persist(rep_dir, wf_result, job_output)

    print("All done. Going to kill other processes")
    # run_cmd("jskill all") # TODO?


if __name__ == "__main__":
    args = parse_args()

    exp_conf = OmegaConf.load(Path(args.conf))

    if exp_conf.scheduler_type == "lsf":
        cluster_utils = LsfUtils()
    elif exp_conf.scheduler_type == "slurm":
        cluster_utils = SlurmUtils()
    else:
        raise NotImplementedError()

    nreps = exp_conf.varying_params[args.varying_param_key]["nreps"]

    for rep_no in range(nreps):
        main(
            cluster_utils=cluster_utils,
            exp_conf=exp_conf,
            varying_param_key=args.varying_param_key,
            my_job_id=args.my_job_id,
            rep_no=rep_no,
        )

    proj_dir = exp_conf.static_params.proj_dir
    job_dir = os.path.join(proj_dir, "exps", args.my_job_id)
    os.makedirs(job_dir, exist_ok=True)
    with open(os.path.join(job_dir, "SUCCESS"), "w") as f:
        f.write(datetime.utcnow().strftime("%Y-%m-%d %H-%M-%S.%f")[:-3])

    cluster_utils.kill_this_job()
    sys.exit(0)
